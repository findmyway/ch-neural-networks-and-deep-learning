人的视觉感官是这世上最神奇的事情之一。看看下面这串手写字：

![](http://neuralnetworksanddeeplearning.com/images/digits.png)

大多数人都可以毫不费力地识别出这串数字是504192。看起来似乎是件很容易的事，事实上，在人类的每个脑半球中都有一个初级视觉皮层，也被称作V1层，包含了约1.4亿个神经元，这之间又有数百亿的连接。除此之外还有一系列的视觉皮层，如V2、V3、V4和V5层，负责处理更复杂的图像处理。我们可以把大脑看做是一台超级计算机，在经历了上亿年的进化后，才适应了我们所看到的世界。识别手写数字并不容易。尽管人类非常擅长理解双眼所看到的这世界，但由于识别数字几乎是在潜意识中就完成了，以至于我们并不惊讶人类的视觉神经系统解决了这么复杂的问题。

当你动手去写个程序来解决上面的手写字识别时，你就会明白这个问题有多难了。在我们看来很简单的问题似乎一下子变得相当困难了。想想我们是怎么描述一个数字的，比如“9”，“就是一个圈圈带着一个尾巴~”，不过这个描述很难从算法层面上来描述。当你试图使用更加精细的规则来加以描述时，你会陷入到种种例外、特殊情况等等复杂的细节中。唉，似乎很绝望......

神经网络通过另外一种办法来解决这个问题。其核心思想是使用下图所示大量的手写数字作为训练样本。

![](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)

然后，训练系统从上面的样本中去学习。也就是说，神经网络使用样本来自动学习识别手写字说使用的规则。也就是说，通过增加训练样本，神经网络能够从手写字中学到更多，从而提高准确率。尽管上面只列出了100幅图，不过我们可以通过成千上万的样本学习。

在本章，我们会写一个程序来构建神经网络识别这些手写字。整个程序只有72行，而且并没有采用其他的神经网络工具包。但使用这个程序就能够是我们识别数字的准确率达到96%以上。在接下来的章节中，我们会继续深入，将准确率提高到99%以上。事实上，最好的商业神经网络系统已被用在银行支票和邮局的手写字识别系统中。

本书专注于手写字的识别，这是因为在神经网络系统的学习中，手写字的识别是个比较基本的问题，其主要好处在于，这个问题有一定的挑战性――既不太简单，但也不需要多么高深的解决方案或是强大的计算能力。而且通过这个问题还可以学到一些其它的高级技巧，比如深度学习。因此呢，手写数字的识别将贯穿全书。在本书接下来的内容中，我们会讨论如何将这些思想运用到计算机视觉以及语音和自然语言处理等其它领域中。

当然，如果本章仅仅是写一个程序来解决手写数字识别的问题，那么这一章将会短得多。但在这里我们会介绍许多神经网络中的核心基础概念包括两种类型的人工神经元（感知器和sigmoid神经元），以及标准的神经网络算法如SGD（stochastic gradient descent）本章主要是讲清楚为什么它们是这个样子的，再此基础之上，构建对于神经网络的认识。这比简单地告诉你神经网络工作原理要稍微显得嗦一些，不过这会让你对神经网络有更深入的认识，我认为这是值得的。最后我们来理解深度学习究竟是什么以及为什么它如此重要。

##感知器

什么是神经网络呢？首先，来介绍一类人工神经元，感知器。感知器最早由[Frank Rosenblatt](http://en.wikipedia.org/wiki/Frank_Rosenblatt) 在 [Warren McCulloch](http://en.wikipedia.org/wiki/Warren_McCulloch)和[Walter Pitts](http://en.wikipedia.org/wiki/Walter_Pitts)的[研究](http://scholar.google.ca/scholar?cluster=4035975255085082870)基础上[提出](http://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ)来的。在如今的一些神经网络中，一类称为*sigmoid 神经元*的人工神经元用得更多，本书和一些现代的神经网络中也主要使用这类神经元。不过要想理解为什么sigmoid神经元是这么定义的，我们需要先深入了解下感知器的原理。

那，感知器是怎么工作的呢？一个感知器接收一些二值化的输入$x_1,x_2,\ldots$,然后产生一个二值化的输出：

![](http://neuralnetworksanddeeplearning.com/images/tikz0.png)

上面这个例子中，感知器有三个输入，$x_1,x_2,x_3$。当然，输入的个数可以更多或者更少。Rosenblatt提出了一个简单的规则来计算输出。他引入了*权重*，$w_1,w_2,\ldots$,来描述输入对于输出的影响程度。感知器的结果要么是0要么是1，其值是由输入层的加权和$\sum_j w_j x_j$ 是否大于某一阈值来决定的。和权值一样，阈值也是感知器的一个参数。用数学的表达方式来描述就是下面这个式子。
<p>
\begin{eqnarray}
  \mbox{output} & = & \left\{ \begin{array}{ll}
      0 & \mbox{if } \sum_j w_j x_j \leq \mbox{ threshold} \\
      1 & \mbox{if } \sum_j w_j x_j > \mbox{ threshold}
      \end{array} \right.
\tag{1}\end{eqnarray}
</p>

这是最基本的数学模型。你可以这么理解，感知器就是把你所知道的信息通过加权后用来做决策。举个简单的例子，比如，周末马上就要到了，市区会有个奶酪节，你很喜欢奶酪，不知道去还是不去。你需要综合考虑下面三个因素：

1. 天气好不好？

2. 你男朋友或者女朋友陪不陪你一起去？

3. 举办奶酪节的地方交通方不方便？

我们可以用变量$x_1，x_2$和$x_3$来表示这三个因素。例如，如果天气好的话那么$x_1=1$，否则的话$x_1=0$，类似的$x_2=1$表示你男朋友或者女朋友想一起去，否则的话$x_2=0$,$x_3$也类似。

现在假设你非常喜欢奶酪，所以呢，木有女朋友陪也没关系，哈哈。但是你很在意天气，如果天气很差的话你是不会去的。你可以用感知器来描述这个决策。一种方法是，给天气赋权值$w_1=6$，另外两个变量$w_2=2$，$w_3=2$分别代表另外两个条件。天气的权值较大，意味着天气的因素对你来说更重要，比女朋友的因素更重要哦~最后，我们设定这个感知器的阈值是5。也就意味着，天气好的话感知器的输出是1，天气不好的话，感知器的输出是0，至于女朋友去不去，交通方不方便这些都不重要了。

通过改变权值和阈值，我们能得到不同的模型。例如，假设阈值是3，这就意味着，a.天气好 b.女朋友一起去而且交通方便 这两个条件中任何一个成立时，你都会去。也就是说，这变成了另外一个不同的模型，降低阈值意味着你更想去参加这个奶酪节。

很明显，感知器并不是描述人类做决策的完整模型。但上面的例子描述了感知器是如何对不同的因素加权后用于最终决策的过程。我们有理由相信一个完整的感知器网络可以用来做决策。

![](http://neuralnetworksanddeeplearning.com/images/tikz1.png)

上面这个神经网络中的第一层，对输入作加权求和。那么第二层呢？第二层的感知器对第一层感知器的输出做加权求和。也就是说，第二层感知器相比第一层的感知器而言，要在更加复杂而抽象的层面做出决策。第三层的感知器做更复杂的决策。这就意味着，多层的神经网络可以模拟一个相当复杂的决策。

一开始定义感知器的时候，我们说感知器只有一个输出，但是上面的神经网络看起来似乎有不止一个输出。事实上，这些感知器仍然只有一个输出，只不过，上面那些感知器输出上的箭头是为了表示该输出又作用到下一层的输入上了，这样子画看起来简洁一些，不然我们得先画一个输出然后该输出又分裂并连接到下一层的输入。

简单描述一下感知器。前面的描述$\sum_j w_j x_j > threshold$ 显得有些累赘。我们可以进一步将其简化。首先，将$\sum_j w_j x_j$ 改写为向量的点乘形式。$w \cdot x \equiv \sum_j w_j x_j$,其中$w$和$x$分别表示权值和输入的向量。另一个改变是将threshold移到不等式的另一边，同时用另外一个叫做*偏差*的变量来代替，其中$b \equiv - threshold$。最后感知器模型被改写为下面的式子：

<p>
\begin{eqnarray}
  \mbox{output} = \left\{ 
    \begin{array}{ll} 
      0 & \mbox{if } w\cdot x + b \leq 0 \\
      1 & \mbox{if } w\cdot x + b > 0
    \end{array}
  \right.
\tag{2}\end{eqnarray}
</p>

你可以把偏差看做是感知器偏向于输出1的程度，换个说法，就是激活感知器的程度。对于一个有较大偏差的感知器来说，更容易输出1，而对于偏差值很小（一个很小的负数）的感知器来说，很难输出1.添加对**偏差**的描述只是我们对感知器的改进之一，接下来会看到更多的简化。在后面的内容中，本书不再使用**阈值**，而是**偏差**。

我们提到了感知器可以用来做决策，除此之外，还可以用来做一些逻辑运算，如 与、或、非等操作。例如，假设一个感知器有两个输入，每个的权重是-2，同时偏差是3.如下图所示：

![](http://neuralnetworksanddeeplearning.com/images/tikz2.png)

可以看到输入$0,0$ 的结果是 $1$, 因为$(-2)*0+(-2)*0+3=3$是大于0的正数。类似的运算可以得到$输入 0 1 和 1 0 都会得到结果 1$, 但是输入1 1 会得到结果0，因为$(-2)*1+(-2)*1+3=-1$是个负数。这样我们便得到了一个**与非门**。

上面的这个例子表明，我们可以用感知器来计算简单的逻辑关系。事实上，我们可以感知器网络来描述任意的逻辑关系。这是因为，呵呵，学过离散数学你就懂了。通过与非门可以构造出任意的逻辑关系。例如，构造一个计算按位求和的电路。$x_1 \oplus x_2$，当$x_1 和x_2都是1的时候，进位标识（carry）为1$

![](http://neuralnetworksanddeeplearning.com/images/tikz3.png)

我们用感知器网络来表述上面的电路图如下。

![](http://neuralnetworksanddeeplearning.com/images/tikz4.png)

上面这个图中，值得注意的一点是，最左边那个感知器的输出传递了两倍给给下面那个感知器的输入。在前面定义感知器模型的时候，并没有提到是否可以这样子做。事实上，这对整个模型并没有什么影响。如果模型本身并不允许输入多个来自同一感知器输出的话，那么我们可以简单地将这两条线融合成一条线，然后调整权值为原来的两倍就行了。这样，就变成了下图：（注意权重的变化）

![](http://neuralnetworksanddeeplearning.com/images/tikz5.png)

到目前为止，我们一直将$x_1 和 x_2$ 作为一个变量放在网络的最左边，事实上，我们可以将其作为网络的输入层，如下图表示：

![](http://neuralnetworksanddeeplearning.com/images/tikz6.png)

对于输入层的感知器来说，它只有输出没有输入。

![](http://neuralnetworksanddeeplearning.com/images/tikz7.png)

其实，输入层的感知器不过是一个普通的感知器。我们可以这么来看。既然输入为零，那么也就是说$\sum_j w_j x_j$的和为0，然后如果$b>0$的话，输出为1，如果$b \leq 0$，输出为0。也就是说，输入层的感知器只是简单的输出一个固定值，而不受变量($x_1 ...$)等的影响。简单理解为输入我们想要的值，如$x_1,x-2,x_3 ...$

加法器的例子展示了神经网络是怎样用于模拟与非门的，由于一般的运算都可以通过与非门来完成，因此我们可以理解为感知器可以完成任意的计算。感知器的通用性这点既让人兴奋又让人感到有些沮丧，说兴奋是因为感知器可以和其他设备一样强大完成任意计算，说沮丧是因为，感知器不过是又一种形式的与非门罢了。这可不是什么新鲜事。

不过呢，情况要比表面上看上去的要好点。我们可以设计出一种学习算法让感知器组成的网络自动去学习权重和偏差的大小。所有的过程由外部的输入来主导，程序员并不涉及内部的具体过程。这种学习算法使得我们能够以一种不同于对待逻辑运算器的方式来使用感知器。从而轻松解决传统中由逻辑与或非组成的集成电路所不能解决的问题。

##sigmoid神经元
学习算法听起来很牛但是我们怎么利用神经网络来实现呢？假设我们已经有一个由感知器组成的网络，例如，输入可能是一些扫描的数字图像中的像素值。我们希望该网络能够自动学习权重和偏差从而利用其输出来对数字分类，以达到识别的目的。首先来了解下学习的过程。假设我们对神经网络中的权值或者偏差施加一个小的扰动，我们希望这个扰动对神经网络的输出也会产生一个小的扰动，待会就能看到这个特性让自动学习的过程变成可能。下图是一个简单的说明：

![](http://neuralnetworksanddeeplearning.com/images/tikz8.png)

现在假设权值上很小的改变对于输出结果也只有小的改变，那么我们就能利用这个特性得到我们想要的结果。具体来说是这样子的，假设该神经网络错误地将数字9识别成了数字8，通过改变神经网络中某些权值，我们能够微弱地改变输入使得其结果更倾向于将数字识别成9.重复这个过程，并反复改变权值，那么我们最终就能得到想要的结果。同时意味着该神经网络完成了自我学习的过程。

但现在的问题是，如果采用感知器构成的神经网络，并没有前面提到的那种特性。事实上，网络中对权值或者偏差的任何微弱扰动，最终会导致感知器的输出发生很大的突变，比如从0跳变到1。这会使得整个网络的输出变得非常复杂而且不稳定。比如，通过对权值做一个微小的调整，这幅图可能准确地识别成为了9，但是这组权值对于剩下的所有图像的识别结果可能全都变了。这种突变很难让我们以一种渐变的方式去修改权值以得到想要的结果。也许有那么一种方法可以解决这个问题，但目前为止还没有一种很有效的方法来让神经网络在这样的情况下学习。

不过，我们可以通过引入一种新的神经元――“sigmoid神经元”来解决上面的问题。“Sigmoid神经元”和感知器很像，不过呢，权值和偏差的微弱改变对于其输出也只会产生微弱的改变。这就使得由sigmoid神经元构成的网络恩呢该个自适应地去学习权值。

首先来描述一下sigmoid神经元：

![](http://neuralnetworksanddeeplearning.com/images/tikz9.png)

和感知器一样，sigmoid神经元也有输入$x_1,x_2,\ldots$但是，它的输出不再是0或者1 。而是输出0到1之间的某个值。例如0.638等等。类似的，sigmoid神经元也有权值$w_1,w_2,\ldots$以及一个全局偏差b。但是输出不再是0或者1，而是$\sigma(w \cdot x+b)$ 其中$\sigma$叫做**sigmoid函数**，其定义如下：

> 有时候，$\sigma$也称为**逻辑函数，这种类型的神经元也被称为逻辑神经元。记住这个术语有时候很有用，那些学术背景为神经网络方面的人往往会用这个概念。不过下面我还是会使用sigmoid神经元这个术语。

<p>
\begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}}.
\tag{3}\end{eqnarray}
</p>

为了将上面的式子表述得更清楚点，我们用输入$x_1,x_2,\ldots$和权重$w_1,w_2,\ldots以及偏差b$来表述：

<p>
\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
\tag{4}\end{eqnarray}
</p>

乍看上去，sigmoid神经元和感知器很不一样。如果你对sigmoid函数不熟的话，上面这个式子可能让人感觉高深莫测。实际上，sigmoid神经元和前面的感知器有很多相似之处。而且上面那个虽然看起来很高深，其实只是一些数学上的处理技巧罢了，理解起来并不困难。

先来说明下和感知器模型的相似之处。假设$z \equiv w \cdot x + b$是一个很大的正整数，那么$e^{-z} \approx 0$ 从而$\sigma(z) \approx 1$。也就是说，当$z=w \cdot x + b$是一个很大的正数时，sigmoid神经元的输出接近于1.也就和感知器是一样的了。类似的，假设$z = w \cdot x +b $是一个很大的负数，那么$\sigma^{-z} \rightarrow \infty$ 从而$\sigma(z) \approx 0$。也即是说，当$z=w \cdot x + b $是一个很的负数时，sigmoid神经元的输出也非常接近感知器的输出。只有当$w \cdot x + b $的值位于0附近的时候，它的输出才和感知器有很大差别。

那么怎么理解sigmoid函数呢？事实上$\sigma$函数的具体形式并不重要，重要的是这个函数的形状，如下图所示：

<script src="http://d3js.org/d3.v2.min.js"></script>

<div id="sigmoid_graph"></div>

<script>
function s(x) {return 1/(1+Math.exp(-x));}
var m = [40, 120, 50, 120];
var height = 290 - m[0] - m[2];
var width = 600 - m[1] - m[3];
var xmin = -5;
var xmax = 5;
var sample = 400;
var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
var data = d3.range(sample).map(function(d){ return {
        x: x1(d), 
        y: s(x1(d))}; 
    });
var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
var y = d3.scale.linear()
                .domain([0, 1])
                .range([height, 0]);
var line = d3.svg.line()
    .x(function(d) { return x(d.x); })
    .y(function(d) { return y(d.y); })
var graph = d3.select("#sigmoid_graph")
    .append("svg")
    .attr("width", width + m[1] + m[3])
    .attr("height", height + m[0] + m[2])
    .append("g")
    .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
var xAxis = d3.svg.axis()
                  .scale(x)
                  .tickValues(d3.range(-4, 5, 1))
                  .orient("bottom")
graph.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0, " + height + ")")
    .call(xAxis);
var yAxis = d3.svg.axis()
                  .scale(y)
                  .tickValues(d3.range(0, 1.01, 0.2))
                  .orient("left")
                  .ticks(5)
graph.append("g")
    .attr("class", "y axis")
    .call(yAxis);
graph.append("path").attr("d", line(data));
graph.append("text")
     .attr("class", "x label")
     .attr("text-anchor", "end")
     .attr("x", width/2)
     .attr("y", height+35)
     .text("z");
graph.append("text")
        .attr("x", (width / 2))             
        .attr("y", -10)
        .attr("text-anchor", "middle")  
        .style("font-size", "16px") 
        .text("sigmoid function");
</script>

上面这个形状实际上是0-1函数的一个平滑后的效果：

<div id="step_graph"></div>

<script>
function s(x) {return x < 0 ? 0 : 1;}
var m = [40, 120, 50, 120];
var height = 290 - m[0] - m[2];
var width = 600 - m[1] - m[3];
var xmin = -5;
var xmax = 5;
var sample = 400;
var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
var data = d3.range(sample).map(function(d){ return {
        x: x1(d), 
        y: s(x1(d))}; 
    });
var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
var y = d3.scale.linear()
                .domain([0,1])
                .range([height, 0]);
var line = d3.svg.line()
    .x(function(d) { return x(d.x); })
    .y(function(d) { return y(d.y); })
var graph = d3.select("#step_graph")
    .append("svg")
    .attr("width", width + m[1] + m[3])
    .attr("height", height + m[0] + m[2])
    .append("g")
    .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
var xAxis = d3.svg.axis()
                  .scale(x)
                  .tickValues(d3.range(-4, 5, 1))
                  .orient("bottom")
graph.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0, " + height + ")")
    .call(xAxis);
var yAxis = d3.svg.axis()
                  .scale(y)
                  .tickValues(d3.range(0, 1.01, 0.2))
                  .orient("left")
                  .ticks(5)
graph.append("g")
    .attr("class", "y axis")
    .call(yAxis);
graph.append("path").attr("d", line(data));
graph.append("text")
     .attr("class", "x label")
     .attr("text-anchor", "end")
     .attr("x", width/2)
     .attr("y", height+35)
     .text("z");
graph.append("text")
        .attr("x", (width / 2))             
        .attr("y", -10)
        .attr("text-anchor", "middle")  
        .style("font-size", "16px") 
        .text("step function");
</script>

如果$\sigma$是一个0-1函数的话，那么sigmoid神经元实际上就是一个感知器，因为输出就是0或1，由输入$w \cdot x + b$的正负决定。实际上，最关键的地方是$\sigma$函数的平滑程度而不是它的具体形式。$\sigma$的平滑程度以为着$\Delta w_j\$和$\Delta b$的微小变化会对$\Delta output $产生一个小的改变。可以将$\Delta output$近似地表示成下式：

<p>
\begin{eqnarray} 
  \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
  \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b,
\tag{5}\end{eqnarray}
</p>

其中，求和符号是指对所有的权重$w_j$求和，而$\partial output / \partial w_j 和 \partial output /  \partial b$分别表示output对$w_j和b$的偏导。啊哦，不知道什么是偏导？（赶紧复习下微积分去）尽管上面的表达是看起来有点复杂，但是，它所表达的意思很简单：$\Delta output 是 \Delta w_j 和 \Delta b$的线性函数。这种线性关系使得我们可以通过对权重和偏差做一些小的改变从而得到我们想要的输出的改变。因此相比感知器而言，sigmoid神经元更容易看出改变权重和偏差是如何影响输出的。

那么既然重要的是$\sigma$函数的形状而不是其具体的表达式，那么为什么恰恰使用等式3呢？实际上在后面我们还会使用另外一种形式的激活函数$f(w \cdot x + b)$，最主要的一个变化是，等式5的偏导不同了，对比$\sigma$函数，我们后面将要使用的那种函数的偏导形式要比等式5所表示的$\sigma$函数偏导形式复杂很多。事实上，在神经网络中，sigmoid函数是最常用的一种神经元，因此在本书的后面我们也主要采用这种形式的激活函数。

那么怎么解释sigmoid神经元的输出呢？sigmoid神经元的输出和感知器输出的最大区别在于，它的输出不再是0或者1，而是介于0到1之间的一个值。比如0.173...或者0.689等等。这个特性很有用，比如，我们将一幅图像的所有像素点作为神经网络的输入，然后，用神经网络的输出来表示这幅图像素点的平均强度，输出一个0到1之间的值就有了很好的物理解释（如果是感知器的话，只会输出0或者1，这样就不知道强度究竟是多少了）。不过有时候输出一个0到1之间的值也会存在问题，比如我要通过一幅图的所有像素点来判断这幅图是不是数字“9”，显然我们希望神经网络的输出是0还是1，来表示yes or no，也就是感知器那样的二值输出，但是对于sigmoid构成的神经网络而言，其输出为0到1之间的一个值，那么到底是数字“9”还是不是的呢？在实际中，我们通常将感知器的输出小于0.5的时候解释为0，而大于0.5的时候解释为1，也即是说如果sigmoid构成的神经网络的输出如果是大于0.5的值那么久意味着该幅图像表示数字“9”如果输出小于0.5那么就认为该幅图像的输出不是“9”。

##练习

- sigmoid神经元模拟感知器，（part1）
  
  证明：将一个由感知器构成的神经网络中所有权值和偏差都乘以一个正数c后，该网络的特性不变。（c>0）

- sigmoid神经元模拟感知器，（part1）
  和前面的问题一样，假设我们的神经网络还是由感知器构成。选定前面所有感知器的输入，对于感知器中的任何一个输入x都满足$w \cdot x + b \neq 0$ 。然后将所有的感知器换成sigmoid神经元，然后将所有的权重和偏差都乘以一个常数c（c>0）。证明：当$c \rightarrow \infty$时，sigmoid神经元构成的神经网络和感知器构成的神经网络是一样的。如果$w \cdot x + b = 0$时，为什么就不成立了呢？


